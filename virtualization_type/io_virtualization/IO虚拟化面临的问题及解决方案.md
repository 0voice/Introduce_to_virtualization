# I/O虚拟化面临的问题及解决方案

## I/O虚拟化的难点
在讨论用于虚拟化的系统级别的硬件解决方案之前，我们需要确定驱动这些功能的动机。 要理解这些问题，我们必须认识到，以某种方式与I/O进行通信
虚拟化环境是一个悖论。 我们希望在沙盒环境中运行一个操作系统，而该操作系统不会在虚拟环境之外运行该系统。 但是I/O不能忽略外部环境，因为它正在与该环境通信。 因此，可以理解地虚拟化I/O成为一个难题。 因此，从哲学问题出发，虚拟化的目标是什么？I/O如何适应该目标？ 在我看来，这是提供一种托管环境来托管VM，从而改善整体用户体验。 为了实现此目标，理想情况下，我们希望VM中的I/O具有以下属性：

1. 来宾有权访问在本机环境中将使用的相同I/O设备。
2. 来宾操作系统不能影响其他来宾的I/O操作或内存。
3. 对来宾操作系统的软件更改必须最少。
4. 来宾操作系统需要能够从硬件故障或VM迁移中恢复。
5. 来宾OS上的I / O操作应具有与本机运行类似的性能。

在此列表中，我们可以看到列表中的几个项目如何与列表中的其他项目竞争。 因此，最终解决方案将需要根据特定用例进行权衡。 现在，带着这些目标，让我们看一下实现I/O虚拟化的各种技术以及所面临的问题。

## 仿真或半虚拟设备
实施完全虚拟化时，最简单的选择之一是让客户机OS在主机上模拟虚拟设备。 来宾与该虚拟设备进行通信，并且管理程序会检测到来宾的通信。 这可以通过捕获设备访问权限或对某些内存页面的权限来完成。 系统管理程序了解来宾OS在虚拟设备上的操作，并在物理设备上执行相应的操作。 该技术称为托管或拆分I/O。

![image](https://user-images.githubusercontent.com/87458342/134525055-f68210cf-0817-42b5-8a7d-e2747066ebd5.png)

该技术的优势在于，由于每个调用都通过管理程序，因此管理程序可以提供所需的功能。 例如，管理程序可以跟踪设备当前正在等待的每个I/O操作。 类似地，简化了限制来宾影响其他来宾的过程，因为所有物理设备访问均由管理程序管理。 但是此技术具有很高的CPU开销。 数据需要多次复制，通过多个I/O堆栈进行处理等。使用半虚拟化可以提高性能。 在这种情况下，操作系统中的设备驱动程序将通过管理程序实现ABI。 设备驱动程序与虚拟机管理程序接口，并且虚拟机管理程序直接与物理设备通信，如下图所示。

![image](https://user-images.githubusercontent.com/87458342/134525111-f19694cc-550e-4314-a83d-0eaed3ca6373.png)

该技术通过类似的控制提供了更好的性能，但是仍然存在相当大的性能开销，例如在捕获到管理程序时。 下图显示了IBM在KVM中使用仿真IDE控制器与IBM virtio-blk半虚拟化设备驱动程序所观察到的差异。

![image](https://user-images.githubusercontent.com/87458342/134525169-b9a7e29b-8824-4bdf-9abc-2618998d6412.png)

在查看此开销时，请务必记住，它与用例密切相关。 CPU约束的基准测试对I/O虚拟化不会表现出太大的敏感性。 另外，对于I/O繁重的基准测试，此开销可能会很大。 作为示例，用于求解线性方程组的共轭梯度方法在用户模式下花费了大约70％的CPU周期，并在参与磁盘I/O的管理程序内核中花费了剩余时间。

## 直通I/O

直通I/O通过重新映射来宾页表直接写入物理设备来大大提高性能。 这消除了为每个操作捕获到虚拟机监控程序的大部分开销。 这种技术使大量的I/O处理达到了接近本机的速度。

![image](https://user-images.githubusercontent.com/87458342/134525467-36ea5f3c-f236-425e-945e-fc5c76cfc9cc.png)

要使用此技术有效地虚拟化I/O，需要解决几个问题。 考虑来宾使用DMA访问与设备通信的情况。 在这种情况下，我们需要考虑以下问题。

## 隔离
虚拟化的目标是对来宾操作系统进行沙箱处理，以防止其访问其他来宾操作系统的数据。 我们通过添加第二阶段翻译在来宾中进行此操作。 但是，DMA设备在物理地址上运行，并且不知道第二阶段的转换。 因此，如果为来宾提供了对DMA设备的不受限制的访问权限，则它可以读取或写入内存中的任何物理地址，并破坏其他来宾的内存。 因此，需要建立一种保护机制，以确保设备仅将来自特定来宾的DMA请求定向到与该来宾关联的内存。 此外，一个以上的访客可能需要访问同一设备。 该设备需要能够区分来自不同设备的访问，并正确地重定向它们。

## 实际地址
为了完成DMA事务，客户机OS需要为设备提供内存中的正确物理地址以查找数据。 但是访客不知道数据的物理地址，只有中间的物理地址（IPA）实际上是虚拟地址。 为了使DMA访问正常工作，设备必须能够将IPA转换为正确的物理地址。

## 连续内存块
仅给设备提供正确的PA不能解决该问题。 设备期望DMA目标区域位于内存的连续区域中。 在虚拟环境中，无法保证。 系统管理程序可以以不超过4K的块分配不连续的访客页面。 因此，设备必须能够对整个DMA区域执行此转换。

## 较大地址空间中的32位设备
此问题类似于上一篇文章中讨论的在64位主机上使用32位来宾的问题。 系统可能具有无法访问较新系统的完整较大地址空间的较旧设备。 使用这些设备的DMA超出其正常可寻址范围时，必须进行地址转换。

## 硬体支援
上面提到的问题很难用软件解决，需要硬件解决方案将设备地址正确映射到正确的客户。 大多数平台都为此提供了硬件解决方案。 此机制称为IO内存管理单元的IOMMU 。 英特尔称其实施为VT-d，AMD称其实施为AMD-Vi，ARM称其实施为SystemMMU。 IOMMU的基本思想很简单。 地址转换单元放在来宾OS可以使用的任何设备之间。 当管理程序为访客OS设置第二阶段页面表以访问设备时，它也将设置IOMMU。 与核心中的走道相似，地址翻译非常昂贵。 因此，实现TLB可以减少地址转换的开销。

![image](https://user-images.githubusercontent.com/87458342/134525714-52a96131-7d8f-4f4f-b209-b85fd2e130ed.png)

显示系统MMU可以放置位置的示例系统。 与设备的事务通过系统MMU进行翻译。

## 系统MMU

ARM系统MMU用不同的转换上下文编程。 通过与预期流进行匹配，它将每个事务映射到相应的上下文。 根据上下文，系统MMU可能会绕过转换，导致故障或执行转换。 ARM体系结构中的System MMU提供了完整的2阶段翻译支持（如上一篇文章中所述），并且根据上下文，我们可以进行第一阶段翻译或第二阶段翻译。 为了执行转换，系统MMU具有类似于TTBR的寄存器和每个上下文的其他控制寄存器。

系统MMU在其转换过程中或未设置上下文时也可能会收到故障。 根据故障的类型以及系统MMU的配置方式，它可能会采取某些措施。 翻译错误会触发中断。 这为虚拟机管理程序提供了处理中断并重新启动转换的机会，以便它可以完成。 系统MMU也可以将BUSERROR发送给适当的请求者。 存在综合症寄存器以简化诊断和解决问题的过程。

System MMU的某些优势甚至不需要虚拟化。 由于系统MMU使每个设备都能执行VA到PA的转换，因此驱动程序可以在用户空间中使用VA执行I / O操作。 权限检查和转换映射可以确保一个用户应用程序不会破坏另一应用程序的内存。 这将消除当前所需的内核陷阱，从而进一步减少I / O开销。 另一个问题是处理连续内存。 许多操作导致非常大的DMA访问，而OS无法将其分配给单个内存块。 当前，它们需要被拆分成多个DMA请求，或者需要通过复杂的DMA分散收集操作来执行。 系统MMU使设备可以通过基于连续VA而不是分段PA的DMA进行通信。 这既减少了CPU开销，又简化了软件和设备。

应该注意的是，系统MMU是平台的一部分，而不是核心体系结构的一部分。 这意味着它仅影响驱动程序。 因此，许多功能都是实现定义的。 例如，用于匹配流并将其映射到上下文的位是实现定义的。 由于没有用户代码知道系统的这一部分，因此对系统MMU体系结构的更改将不需要那么多的旧代码问题。

因此，使用这些技术，系统管理程序可以根据用例提供虚拟化I / O的适当实现。 到此结束本系列有关虚拟化的第三部分。 本系列文章将在下一篇文章中继续，讨论虚拟化的用例，尤其是ARM在移动领域针对的用例。

有关更多信息，请查看以下资源。

* http://xpgc.vicp.net/course/svt/TechDoc/ch12-IOArchitecturesForVirtualization.pdf
* http://nowlab.cse.ohio-state.edu/NOW/dissertations/huang.pdf
* http://www.ibm.com/developerworks/linux/library/l-virtio/
* http://pic.dhe.ibm.com/infocenter/lnxinfo/v3r0m0/topic/liaat/liaatbestpractices_pdf.pdf
* http://www.mulix.org/lectures/xen-iommu/xen-io.pdf
* http://developer.amd.com/wordpress/media/2012/10/IOMMU-ben-yehuda.pdf
* http://www.arm.com/files/pdf/System-MMU-Whitepaper-v8.0.pdf
* http://software.intel.com/zh-CN/articles/intel-virtualization-technology-for-directed-io-vt-d-enhancing-intel-platforms-for-efficiency-virtualization-of-io-devices
* http://support.amd.com/us/Processor_TechDocs/48882.pdf


原文作者： 程序员大本营









